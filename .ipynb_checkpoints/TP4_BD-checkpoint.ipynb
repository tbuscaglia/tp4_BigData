{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0182c4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "## Parte I ##\n",
    "\n",
    "# 2. Importar datos\n",
    "hogares = pd.read_excel(\"C:/Users/tomas/Documents/UdeSA/Cuarto Año/Primer Cuatri/Big Data/TP4/usu_hogar_T423.xlsx\")\n",
    "\n",
    "hogares = hogares[hogares['AGLOMERADO'].isin([32, 33])]\n",
    "\n",
    "individuos = pd.read_excel(\"C:/Users/tomas/Documents/UdeSA/Cuarto Año/Primer Cuatri/Big Data/TP4/usu_individual_T423.xlsx\")\n",
    "\n",
    "individuos = individuos[individuos['AGLOMERADO'].isin([32, 33])]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12177d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mergear base de individuos con la de los hogares\n",
    "\n",
    "df = pd.merge(hogares, individuos, on=['CODUSU', 'NRO_HOGAR'], suffixes=('_x', '_y'))\n",
    "columns_to_drop = [col for col in df if col.endswith('_y')]\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "df.columns = [col.rstrip('_x') if col.endswith('_x') else col for col in df.columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1781b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Limpiar base\n",
    "\n",
    "#Variable categorica\n",
    "df['MAS_500'] = np.where(df['MAS_500'] == 'S', 1, 0)\n",
    "\n",
    "# Missing values: primero saque missings en p47T y luego elimine las columnas con missing\n",
    "missing_values = df.isna().sum()\n",
    "df = df.dropna(subset=['P47T'])\n",
    "df = df.dropna(axis=1)\n",
    "\n",
    "# Outliers o valores sin sentido\n",
    "\n",
    "df = df[df['CH06'] > 0]\n",
    "\n",
    "cols = ['P47T', 'T_VI' , 'ITF', 'IPCF']\n",
    "\n",
    "for i in range(0, len(cols)):   \n",
    "    plt.figure(figsize = (10, 6))\n",
    "    df.boxplot(column = cols[i])\n",
    "    plt.title(cols[i])\n",
    "    plt.xticks(rotation = 45)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0169608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Variables para predecir pobreza\n",
    "\n",
    "#Propocion de niños en el hogar\n",
    "casa = df.groupby('CODUSU')\n",
    "total_personas = casa.size()\n",
    "child = casa.apply(lambda x: (x['CH06'] < 18).sum())\n",
    "proporcion_jovenes = child/total_personas\n",
    "proporcion_jovenes = proporcion_jovenes.reset_index(name='proporcion_jovenes')\n",
    "df = pd.merge(df, proporcion_jovenes, on='CODUSU')\n",
    "\n",
    "#Proporcion de personas que trabajan\n",
    "trabaja = casa.apply(lambda x: (x['ESTADO'] == 1).sum())\n",
    "proporcion_trabaja = trabaja/total_personas\n",
    "proporcion_trabaja = proporcion_trabaja.reset_index(name='proporcion_trabaja')\n",
    "df = pd.merge(df, proporcion_trabaja, on='CODUSU')\n",
    "\n",
    "#Proporcion de personas que saben leer y escribir\n",
    "leer_escribir = casa.apply(lambda x: (x['CH09'] == 1).sum())\n",
    "proporcion_leer = leer_escribir/total_personas\n",
    "proporcion_leer = proporcion_leer.reset_index(name='proporcion_leer')\n",
    "df = pd.merge(df, proporcion_leer, on='CODUSU')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea0e639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Estadisticas Descriptivas\n",
    "\n",
    "desc = ['ITF', 'NIVEL_ED', 'P21', 'proporcion_jovenes', 'proporcion_trabaja']\n",
    "\n",
    "def format_stats(stats):\n",
    "    return stats.apply(lambda x: \"{:,.2f}\".format(x) if isinstance(x, (int, float)) else x)\n",
    "\n",
    "for column in desc:\n",
    "    desc_stats = df[column].describe().to_frame().T\n",
    "    formatted_stats = format_stats(desc_stats)\n",
    "    print(f\"Estadistica descriptiva para '{column}':\")\n",
    "    print(formatted_stats.to_string(index=False))\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0080db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Relacion entre variables\n",
    "\n",
    "#P47T y CH06\n",
    "\n",
    "pr = df[df['P47T'] < 1000000]\n",
    "\n",
    "plt.scatter(pr['CH06'], pr['P47T'], alpha=0.5)\n",
    "plt.title(\"Scatter Plot of CH06 and P47T\")\n",
    "plt.ylabel(\"P47T\")\n",
    "plt.xlabel(\"CH06\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d69ec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Necesidades energeticas\n",
    "\n",
    "bins = [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 29, 45, 60, 75, float('inf')]\n",
    "labels = [\n",
    "    'less_than_1', '1_year', '2_year', '3_year', '4_year', '5_year', '6_year', '7_year', '8_year', '9_year', '10_year', \n",
    "    '11_year', '12_year', '13_year', '14_year', '15_year', '16_year', '17_year', '18_to_29', '30_to_45', \n",
    "    '46_to_60', '61_to_75', 'more_than_75'\n",
    "]\n",
    "\n",
    "df['age_group'] = pd.cut(df['CH06'], bins=bins, labels=labels)\n",
    "\n",
    "#Dummie por genero y edad\n",
    "for sex in [1, 2]:\n",
    "    for label in labels:\n",
    "        dummy_name = f'sex_{sex}_age_{label}'\n",
    "        df[dummy_name] = ((df['CH04'] == sex) & (df['age_group'] == label)).astype(int)\n",
    "\n",
    "energy_needs = {\n",
    "    'less_than_1': {1: 0.35, 2: 0.35},\n",
    "    '1_year': {1: 0.37, 2: 0.37},\n",
    "    '2_year': {1: 0.46, 2: 0.46},\n",
    "    '3_year': {1: 0.51, 2: 0.51},\n",
    "    '4_year': {1: 0.55, 2: 0.55},\n",
    "    '5_year': {1: 0.60, 2: 0.60},\n",
    "    '6_year': {1: 0.64, 2: 0.64},\n",
    "    '7_year': {1: 0.66, 2: 0.66},\n",
    "    '8_year': {1: 0.68, 2: 0.68},\n",
    "    '9_year': {1: 0.69, 2: 0.69},\n",
    "    '10_year': {1: 0.79, 2: 0.70},\n",
    "    '11_year': {1: 0.82, 2: 0.72},\n",
    "    '12_year': {1: 0.85, 2: 0.74},\n",
    "    '13_year': {1: 0.90, 2: 0.76},\n",
    "    '14_year': {1: 0.96, 2: 0.76},\n",
    "    '15_year': {1: 1.00, 2: 0.77},\n",
    "    '16_year': {1: 1.03, 2: 0.77},\n",
    "    '17_year': {1: 1.04, 2: 0.77},\n",
    "    '18_to_29': {1: 1.02, 2: 0.76},\n",
    "    '30_to_45': {1: 1.00, 2: 0.77},\n",
    "    '46_to_60': {1: 1.00, 2: 0.76},\n",
    "    '61_to_75': {1: 0.83, 2: 0.67},\n",
    "    'more_than_75': {1: 0.74, 2: 0.63}\n",
    "}\n",
    "\n",
    "for sex in [1, 2]:\n",
    "    for label in labels:\n",
    "        dummy_name = f'sex_{sex}_age_{label}'\n",
    "        energy_value = energy_needs[label][sex]\n",
    "        df[dummy_name] = df[dummy_name] * energy_value\n",
    "\n",
    "def get_positive_energy_value(row):\n",
    "    for sex in [1, 2]:\n",
    "        for label in labels:\n",
    "            dummy_name = f'sex_{sex}_age_{label}'\n",
    "            if row[dummy_name] > 0:\n",
    "                return row[dummy_name]\n",
    "    return 0\n",
    "\n",
    "df['adulto_equiv'] = df.apply(get_positive_energy_value, axis=1)\n",
    "\n",
    "df = df.loc[:, ~df.columns.str.startswith('sex_')]\n",
    "\n",
    "df.drop(columns=['age_group'], inplace=True)\n",
    "\n",
    "#Agrupamos por hogar CODUSU  ad equiv hogar\n",
    " \n",
    "df['ad_equiv_hogar'] = df.groupby('CODUSU')['adulto_equiv'].transform('sum')\n",
    "\n",
    "test = df[['CODUSU','CH04', 'CH06', 'adulto_equiv', 'ad_equiv_hogar' , 'ITF']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195bcd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Separar base y clasificar en pobre/no pobre\n",
    "\n",
    "respondieron = df[df['ITF'] > 0].copy()\n",
    "\n",
    "norespondieron = df[df['ITF'] <= 0].copy()\n",
    "\n",
    "respondieron['ingreso_necesario'] = respondieron['ad_equiv_hogar'] * 132853.3\n",
    "\n",
    "respondieron['pobre'] = np.where(respondieron['ingreso_necesario'] > respondieron['ITF'], 1, 0)\n",
    "\n",
    "test = respondieron[['CODUSU','CH04', 'CH06', 'adulto_equiv', 'ad_equiv_hogar' ,'PONDIH', 'ITF', 'ingreso_necesario', 'pobre']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884de0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. PONDIH\n",
    "test = norespondieron[['CODUSU','CH04', 'CH06', 'PONDIH', 'ITF']]\n",
    "\n",
    "hogar = respondieron.drop_duplicates(subset=['CODUSU'])\n",
    "\n",
    "total_hogares = hogar.shape[0]\n",
    "\n",
    "hogares_pobres = hogar['pobre'].sum()\n",
    "\n",
    "proporcion_hogares_pobres = hogares_pobres/total_hogares\n",
    "\n",
    "print('Proporcion de hogares pobres:', proporcion_hogares_pobres)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5e12e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parte II ##\n",
    "\n",
    "# 1. Funcion para evaluar metodo\n",
    "\n",
    "def evaluar_metodo(modelo, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # Realizamos predicción sobre base test\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Matriz de Confusión:\\n\", conf_matrix)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    print(\"AUC del ROC:\", roc_auc)  # AUC of ROC curve\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Precisión (Accuracy):\", accuracy)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='Curva ROC (área = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "    plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "    plt.title('Curva ROC para KNN')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return {\"confusion_matrix\": conf_matrix, \"accuracy\": accuracy, \"roc_auc\": roc_auc}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7ba064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Cross Validation\n",
    "\n",
    "def cross_validation(modelo, k, X, y):\n",
    "    kf = KFold(n_splits=k)\n",
    "    resultados = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        resultado_iteracion = evaluar_metodo(modelo, X_train, X_test, y_train, y_test)\n",
    "        resultados.append(resultado_iteracion)\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4676d499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Evalua Config\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fca80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parte III ##\n",
    "\n",
    "\n",
    "# 1. Pre procesamientio de base \n",
    "cols_ingreso = ['CODUSU', 'ITF', 'IPCF', 'PP06C', 'PP06D', 'PP08D1',  'P21', 'TOT_P12', \n",
    "                'P47T', 'V2_M', 'V3_M', 'V4_M', 'V5_M', 'V8_M',\n",
    "                'V9_M', 'V10_M', 'V11_M', 'V12_M', 'V18_M', 'V21_M', 'T_VI', \n",
    "                'adulto_equiv', 'ad_equiv_hogar', 'CH05', 'PP09A_ESP',\n",
    "                'DECINDR', 'ADECINDR', 'RDECINDR', 'PDECINDR', 'GDECINDR', 'IDECINDR',\n",
    "                'DECOCUR','ADECOCUR','RDECOCUR','PDECOCUR','GDECOCUR','IDECOCUR',\n",
    "                'DECIFR','ADECIFR','RDECIFR','PDECIFR','GDECIFR','IDECIFR','DECCFR',\n",
    "                'ADECCFR','RDECCFR','PDECCFR','GDECCFR','IDECCFR'\n",
    "                ]\n",
    "\n",
    "df_res = respondieron.drop(columns = cols_ingreso + ['ingreso_necesario'], errors='ignore')\n",
    "df_res = df_res.dropna(axis=1)\n",
    "df_nores = norespondieron.drop(columns = cols_ingreso, errors = 'ignore')\n",
    "df_nores = df_nores.dropna(axis=1)\n",
    "\n",
    "X = df_res.drop(columns=['pobre'])  \n",
    "X['intercept'] = 1 \n",
    "y = df_res['pobre'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "knn_test = evaluar_metodo(knn, X_train, X_test, y_train, y_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)  \n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "logit = LogisticRegression(penalty=None, max_iter=1000)\n",
    "\n",
    "logit_test = evaluar_metodo(logit, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "\n",
    "\n",
    "results_cross_validation = cross_validation(knn, 5, X.values, y.values)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### FIJATE SI TENES QUE ESCALAR LOS DATOS ACA O EN LA FUNCION ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456e9679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
